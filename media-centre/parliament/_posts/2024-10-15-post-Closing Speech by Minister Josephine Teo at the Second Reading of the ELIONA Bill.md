---
title: Closing Speech by Minister Josephine Teo at the Second Reading of the
  ELIONA Bill
permalink: /closing-speech-by-minister-josephine-teo-at-the-second-reading-of-the-eliona-bill/
date: 2024-10-15
layout: post
description: ""
image: ""
variant: tiptap
---
<p><strong>SECOND READING CLOSING SPEECH BY MINISTER JOSEPHINE TEO ON THE ELECTIONS (INTEGRITY OF ONLINE ADVERTISING) (AMENDMENT) BILL - 15 OCT 2024</strong>
</p>
<p>1. Mr Speaker, I thank Members for their unanimous support of the Bill.
In fact, Members had expressed concerns about deepfakes even before the
debate on this Bill. We have heard questions in this House about how we
can better tackle impersonation scams. Earlier this year, members Dr Tan
Wu Meng and Ms Mariam Jaafar shared concerns about the impact of deepfakes
on democratic processes and elections.</p>
<p>2. Taken together with today’s debate, there is clear consensus on the
pressing need to deal with the threat of digitally manipulated online content
because of what is at stake: the integrity of our elections.</p>
<p>3. Members have also sought clarifications on several issues. I will try
my best to address them.</p>
<p>4. Some members have asked how the ELIONA Bill compares to other governments’
attempts to tackle deepfakes. Sir, we do take reference from other countries,
but it is more important to be fit-for-purpose. We have therefore scoped
the law to be appropriate for Singapore’s context.</p>
<p>5. Earlier, I mentioned how South Korea bans all political campaign videos
that use AI-generated content 90 days prior to an election. Brazil has
also banned synthetic electoral propaganda.</p>
<p>6. In response to Ms Joan Pereira’s question, we did consider a temporary
ban on all deepfake content of a political nature during elections. After
careful deliberations, we decided this was not necessary.</p>
<p>7. There is nothing inherently wrong if AI is used, for example, to enhance
the background of political communications materials. The key problem is
with digitally generated and manipulated content that misrepresents a candidate’s
words or actions. The Bill therefore targets such content.</p>
<p>8. Members have also asked for the rationale behind the proposed duration
of the ban.</p>
<p>9. Previously, Ms He Ting Ru asked about the recourse for political candidates
affected by deepfakes during Cooling-off or Polling Day in elections. The
ELIONA Bill provides the recourse.</p>
<p>10. But we know that purveyors of deepfakes will not constrain themselves
to just the Cooling-Off Day or Polling Day. If we are to effectively uphold
the integrity of elections, the protections under the Bill must be available
when election activities are the most intense, and mischief makers most
active. This is usually the election period, which is also defined in section
61S of the Parliamentary Elections Act, and section 42R of the Presidential
Elections Act. It starts from the issuance of the Writ of Election and
ends after the close of polling.</p>
<p>11. Mr Yip Hon Weng and Ms He suggested that the proposed duration of
the ban should be longer. I thank them for their suggestion and agree with
both their concerns. Practically speaking, however, even if we wanted ELIONA
to take effect X days before an election, we cannot do so until the Writ
is issued, and Polling Day revealed. This is why we will introduce a Code
of Practice to require specified social media services to implement safeguards
beyond the election period specified in the Bill. This allows for calibration
of the speed of response and the resource requirements outside of election
periods.</p>
<p>12. Let me now deal with the types of content the Bill will and will not
cover.</p>
<p>13. Mr Zhulkarnain Abdul Rahim and Mr Vikram Nair have asked why the ban
was not scoped wider, to cover online election advertising that misrepresents
persons other than candidates. For example, deepfakes that falsely show
key influencers or artistes endorsing a candidate.</p>
<p>14. We considered this carefully. The question is, how influential must
these other persons be for the prohibition to apply? Where do we draw the
line and who decides? As a political contest develops, the dynamics may
also change. How about persons who were previously not influential but
suddenly gained prominence?</p>
<p>15. Similarly, Ms Pereira asked why the new measures only apply to content
that explicitly depicts candidates, and not content that indirectly misrepresents
them. One such example is an AI-generated podcast that discusses their
past. This problem has existed even without AI or digital manipulation.
For example, through coffeeshop talk of people who claim to know something
about the candidate. However, the difference is that deepfake content is
very realistic and hence persuasive. When they directly depict candidates
doing or saying something, the audience is more likely to accept it as
reality. In contrast, hearsay information or third-party accounts like
coffeeshop chatter tend to be discounted, or at least viewed with some
scepticism.</p>
<p>16. There are also practical difficulties in extending the coverage of
the ELIONA Bill outside of content directly depicting candidates’ words
and actions. For example, how do we ascertain the degree of misrepresentation?
The better alternative is to encourage a culture of truthfulness, where
persons of influence and candidates themselves step forward to clarify
to the public if they have been misrepresented through deepfake content.
Voters too must be vigilant and turn to trusted sources such as our mainstream
media.</p>