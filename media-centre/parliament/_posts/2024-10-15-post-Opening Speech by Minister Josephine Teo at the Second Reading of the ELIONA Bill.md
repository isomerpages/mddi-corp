---
title: Opening Speech by Minister Josephine Teo at the Second Reading of the
  ELIONA Bill
permalink: /opening-speech-by-minister-josephine-teo-at-the-second-reading-of-the-eliona-bill/
date: 2024-10-15
layout: post
description: ""
image: ""
variant: tiptap
---
<p><strong>SECOND READING OPENING SPEECH BY MINISTER JOSEPHINE TEO ON THE ELECTIONS (INTEGRITY OF ONLINE ADVERTISING) (AMENDMENT) BILL - 15 OCT 2024</strong>
</p>
<p><strong><u>Introduction</u></strong>
</p>
<p>1. Madam Deputy Speaker, I beg to move, “That the Bill be now read a second
time.”</p>
<p><strong><u>Threat of deepfakes to elections</u></strong>
</p>
<p>2. Madam, 2024 is a bumper year for elections around the world. Almost
half of the world’s population have gone or will go to the polls this year.</p>
<p>3. Unfortunately, there has been a noticeable increase of deepfake incidents
in countries where elections have taken place or are planned. Research
conducted by London-based tech company Sumsub suggests that the numbers
are alarming. In India, compared to a year ago, there are three times as
many deepfake incidents. In Indonesia, more than 15 times and in South
Korea, more than 16 times.<sup>1</sup>
</p>
<p>4. Earlier in January this year, a fake version of U.S. President Joe
Biden’s voice was featured in robocalls that sought to discourage Democrats
from participating in the New Hampshire Primary. The robocalls reached
thousands of people. The US Federal Communications Commission has since
declared AI-generated robocalls illegal, noting that they have the potential
to confuse consumers with misinformation. The telecommunications company
which transmitted the fake robocalls has been fined US$1 million, and the
individual behind it faces a fine of US$6 million and criminal charges.</p>
<p>5. During the Slovakian parliamentary elections last year, a deepfake
audio of a politician discussing electoral rigging was posted online. Unsurprisingly,
the audio went viral. Its impact was amplified by its timing – right before
Slovakia’s electoral “silence period”, which is like our cooling-off day.
The candidate lost the elections, despite having earlier led in the polls.
Did the deepfake audio contribute to his loss? No one can say with certainty,
but surely we prefer not to have elections subject to such incidents.</p>
<p><strong><u>Overseas jurisdictions and industry action</u></strong>
</p>
<p>6. Why have deepfake content proliferated? The short answer is that they
have become very easy and cheap to produce. With your permission, Mr Speaker,
may I play a video on the LED screens?</p>
<table style="minWidth: 25px">
<colgroup>
<col>
</colgroup>
<tbody>
<tr>
<td rowspan="1" colspan="1">
<p><strong>Minister’s deepfake video presentation</strong>
</p>
<p>Hello, it’s been a busy day in the office, and I’ve just had a cup of
coffee.</p>
<p></p>
<p>(Pause) Did you think this was really me, Jo Teo, speaking in this video?
Actually, this is a deepfake generated by artificial intelligence.</p>
<p></p>
<p>It only took one person one hour to create this, using easily accessible
software that anyone can use right now from the Internet.</p>
<p></p>
<p>Imagine if someone produced realistic deepfakes, depicting Members of
this House saying or doing something we did not actually say or do, and
disseminated it. Such technology will only improve, and deepfakes may become
even more realistic, convincing, and easy to make.</p>
</td>
</tr>
</tbody>
</table>
<p>7. Sir, Members will appreciate that AI technology is improving quickly.
If the deepfake video you just watched did not convince you of its impersonation
of me, more advanced versions soon will.</p>
<p>8. Around the world, countries have recognised the need to mitigate the
harms of deepfakes to their elections.</p>
<p>a. For example, South Korea revised its Public Official Election Act to
ban political campaign videos that use AI-generated content 90 days prior
to an election. Violations of the revised law, which took effect in January
this year, can lead to jail time of up to seven years, or a fine of up
to 50 million won, which is almost S$50,000. To date, 388 deepfakes have
been taken down by the National Election Commission of South Korea during
its elections.</p>
<p>b. Another example is Brazil, which has banned synthetic electoral propaganda
that will harm or favour any candidate during an election. The sanctions
include the revocation of the candidate’s registration or their mandate,
if they had been elected.</p>
<p>c. Last month, the state of California passed into law the “Defending
Democracy from Deepfake Deception Act of 2024”, which requires social media
platforms to block materially deceptive deepfakes of candidates from 120
days before the election to the day of the election.</p>
<p>d. The Australian government is also considering the advice of its Electoral
Commission to regulate the use of AI in elections, given the Commission’s
recent warning that it has limited scope to protect voters from deepfake
videos and phone calls imitating politicians in Australia’s upcoming elections.</p>
<p>9. It is not just Governments which are concerned. The tech industry has
also recognised the dangers of electoral deepfakes, and the importance
of ensuring voters can exercise their choice, free from AI-based manipulation.
Twenty leading tech companies, including Meta, Microsoft, OpenAI, and TikTok,
signed the Tech Accord at the Munich Security Conference in February, committing
to combat the deceptive use of AI in elections this year.</p>
<p><strong><u>Upholding the integrity of elections in Singapore</u></strong>
</p>
<p>10. In the face of these developments, Singaporeans are rightly concerned.
One study<sup>2 </sup>shows that more than 6 in 10 Singaporeans are worried
about the potential impact of deepfakes on the next election.</p>
<p>11. In a 2021 ruling on a case related to misinformation and online falsehoods,
our apex court had said: “It is simply incompatible with the core principles
of democracy to procure the outcome of an election to public office or
a referendum by trading in disinformation and falsehoods.”</p>
<p>12. Mr Speaker, I hope Members will agree that AI-generated misinformation
can seriously threaten our democratic foundations and demands an equally
serious response. The Elections (Integrity of Online Advertising) (Amendment)
Bill, or ELIONA, is our carefully calibrated response to augment our election
laws under the Parliamentary Elections Act and the Presidential Elections
Act, ensuring that the truthfulness of candidate representation and the
integrity of our elections continues to be upheld.</p>
<p><strong><u>Scope of the Bill</u></strong>
</p>
<p><em>Key legal requirements</em>
</p>
<p>13. Sir, I will now bring Members through the key aspects of the Bill.</p>
<p>14. The ELIONA Bill will amend our election laws to prohibit the publication
of content that:</p>
<p>a. is or includes online election advertising, or “OEA”;</p>
<p>b. Is digitally generated or manipulated; and</p>
<p>c. depicts a candidate saying or doing something that he or she did not
in fact say or do;</p>
<p>d. But is realistic enough that some members of the public who see or
hear the content would reasonably believe that the candidate did in fact
say or do that thing.</p>
<p>15. I will go through each of these criteria in detail.</p>
<p>16. First, online election advertising under our existing election laws
refers to any information or material published online that can reasonably
be regarded as intended to promote or procure, or prejudice the electoral
success or prospects of a candidate or political party. The existing OEA
provisions guide the transparent and responsible use of the Internet during
elections, including for campaigning, and ensure that the elections are
contested fairly. The ELIONA Bill strengthens the OEA regime by targeting
the substantive content of the OEA.</p>
<p>17. Second, the ELIONA Bill is scoped to address content that is digitally
generated or manipulated. This includes content generated or manipulated
using AI techniques such as generative AI. It also includes non-AI techniques
such as Photoshop, dubbing, and splicing. These are now seen as more traditional
editing methods. But they can still be used to manipulate content depicting
candidates, making them as harmful and misleading as AI-generated deepfakes.</p>
<p>18. Third, the ELIONA Bill is scoped to address the most harmful types
of content in the context of elections, which is content that misleads
or deceives the public about a candidate, through a false representation
of his speech or actions, that is realistic enough to be reasonably believed
by some members of the public.</p>
<p>19. The condition of being realistic will be objectively assessed. There
is no one-size-fits-all set of criteria but some general points can be
made:</p>
<p>a. First, such content should closely match the candidates’ known features,
expressions, and mannerisms. Technically, we would expect a degree of sophistication
resulting in minimal inconsistencies in aspects like lighting, body movements,
or audio distortions.</p>
<p>b. Second, content may make use of actual persons, events and places so
that the false representation appears more believable. For example, a fake
rally speech touching on current affairs looks more real when placed against
the backdrop of an actual and familiar rally site.</p>
<p>c. We must also recognise that audiences perceive and process the same
content through different lenses shaped by their individual experiences,
beliefs, and cognitive biases. For example, many of us find it inconceivable
that the Prime Minister would be giving investment advice on social media.
But as Members of Parliament, we have all met residents who have fallen
prey to such AI-enabled scams. In this regard, the law will apply so long
as there are some members of the public who would reasonably believe that
the candidate did say or do what was depicted.</p>
<p>20. Also, in assessing whether content matches a candidate’s speech or
actions, we will be relying primarily on declarations by the candidate
if he or she had said or done that thing. I will elaborate on this later
in my speech.</p>
<p>21. All four legal limbs have to be met for the content to be prohibited.
That is, the content</p>
<p>a. is or includes OEA;</p>
<p>b. Is digitally generated or manipulated; and</p>
<p>c. depicts a candidate saying or doing something that he or she did not
in fact say or do;</p>
<p>d. But is realistic enough that some members of the public who see or
hear the content would reasonably believe that the candidate did in fact
say or do that thing.</p>
<p>22. Mr Speaker, with your permission, may I ask the Clerks to distribute
a handout that will illustrate our thinking on what will be allowed or
disallowed under the new provisions? Sir, Members can also access this
handout through the MP@SGPARL App.</p>
<p>23. Examples of content that would be prohibited include:</p>
<p>a. Realistic audiofakes featuring a candidate saying things he did not
say;</p>
<p>b. Realistic AI-generated images of a candidate participating at events
that did not happen, meeting people that he or she did not meet;</p>
<p>c. Realistic manipulated images or videos taken out of context and misrepresenting
a candidate’s actions.</p>
<p>24. It does not matter if the content is favourable or unfavourable to
any candidate. The publication of such prohibited content during the election
period, including by boosting, sharing, and reposting existing content,
will be an offence.</p>
<p><em>Assurances on content that are unlikely to be caught</em>
</p>
<p>25. As we propose this new measure to tackle realistic misrepresentations
of candidates online, we are mindful not to disallow reasonable use of
AI or technology in electoral campaigning. While each case will be assessed
on a case-by-case basis, there are several scenarios that the prohibition
will not extend to.</p>
<p>a. The first is AI-generated or animated characters and cartoons. Most
of these animations are not photorealistic replicas of real persons; audiences
will generally be able to tell that the speech or actions depicted are
not real.</p>
<p>b. The second is benign cosmetic alterations, such as the use of beauty
filters, or colour and lighting adjustments of images and videos. Such
alterations typically involve modifications that do not materially affect
truthfulness, and do not result in a misrepresentation of a candidate’s
speech or actions.</p>
<p>c. The third is entertainment content, such as memes. We recognise that
such content can arise as part of online discourse during the election
period. Memes will not be caught under the law as long as they are assessed
to be unrealistic and do not mislead audiences about a candidate’s speech
or actions.</p>
<p>26. Some Members may be concerned – will candidates’ regular campaign
posters, showing individuals against the backdrop of a GRC or a SMC, be
prohibited if they are put online? Such posters are usually obvious composite
images, such as candidates disproportionately superimposed in front of
a landmark or backdrop. Members of the public would not reasonably believe
such content to be realistic depictions of a candidate’s action. Such campaign
posters are unlikely to fall within the scope of prohibitions. Ban will
not apply to certain communications and publications</p>
<p>27. Mr Speaker, I would like to make clear that the ban will not apply
to certain types of content.</p>
<p>28. First, the Bill does not extend to private or domestic communications.
This refers to content shared between individuals or within a closed group,
like group chats with family or a small group of friends, in view of user
privacy.</p>
<p>a. That said, we know that false content can circulate rapidly on open
WhatsApp or Telegram channels. If it is reported that prohibited content
is being communicated in big group chats that involve many users who are
strangers to one another, and are freely accessible by the public, such
communications will be caught under the Bill and we will assess if action
should be taken.</p>
<p>b. The factors that determine whether communications are private or domestic
are set out in the respective election Acts.</p>
<p>29. Second, the prohibition does not apply to news published by authorised
news agencies. This is to give space to fair reporting on prohibited content,
such that the public can be alerted to the false content about candidates
in a timely manner.</p>